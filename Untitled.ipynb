{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "device = torch.device('cpu' if torch.cuda.is_available() else \"cpu\")\n",
    "CFG = {\n",
    "    'batch_size': 128,\n",
    "    'learning_rate': 0.001,\n",
    "    'momentum': 0.9,\n",
    "    'epoch': 1\n",
    "}\n",
    "\n",
    "transformer = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "train_data = CIFAR10('./data', train=True, download=True, transform=transformer)\n",
    "test_data = CIFAR10('./data', train=False, download=True, transform=transformer)\n",
    "train_loader = DataLoader(train_data, batch_size=CFG['batch_size'], shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=CFG['batch_size'], shuffle=True)\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5),  # 28*28\n",
    "            nn.MaxPool2d(2, 2),  # 14 14\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv2d(6, 10, 5),  # 10*10\n",
    "            nn.MaxPool2d(2, 2),  # 5*5\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(5 * 5 * 10, 100),\n",
    "            nn.Linear(100, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(-1, 250)\n",
    "        out = self.fc(out)\n",
    "        out = F.softmax(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def test():\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            target_one_hot = F.one_hot(target,num_classes=10)\n",
    "            output = net(data).to(device)\n",
    "            test_loss += my_loss_function(output, target_one_hot).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "class MyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return torch.mean(torch.pow((x - y), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, Loss):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = F.one_hot(target.to(device),num_classes=10)\n",
    "        optimizer.zero_grad()\n",
    "        output = net.forward(data).to(device)\n",
    "        loss = my_loss_function(output, target)\n",
    "        Loss.append(loss)\n",
    "        loss.backward(retain_graph=True)\n",
    "        for i,parm in enumerate(net.parameters()):\n",
    "            torch.autograd.functional.hessian(loss, parm)\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)] loss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liang\\.conda\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:51: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-e532c3b3b160>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mfirstgrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLoss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLoss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-71-6e7f8a8b7da2>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch, model, Loss)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhessian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\autograd\\functional.py\u001b[0m in \u001b[0;36mhessian\u001b[1;34m(func, inputs, create_graph, strict)\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 548\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjacobian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjac_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_tuple_postprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mis_inputs_tuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_inputs_tuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\autograd\\functional.py\u001b[0m in \u001b[0;36mjacobian\u001b[1;34m(func, inputs, create_graph, strict)\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_grad_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneed_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m     is_outputs_tuple, outputs = _as_tuple(outputs,\n\u001b[0;32m    427\u001b[0m                                           \u001b[1;34m\"outputs of the user-provided function\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\autograd\\functional.py\u001b[0m in \u001b[0;36mjac_func\u001b[1;34m(*inp)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mjac_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 544\u001b[1;33m         \u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjacobian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_single_output_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    545\u001b[0m         \u001b[0m_check_requires_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"jacobian\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\autograd\\functional.py\u001b[0m in \u001b[0;36mjacobian\u001b[1;34m(func, inputs, create_graph, strict)\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_grad_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneed_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m     is_outputs_tuple, outputs = _as_tuple(outputs,\n\u001b[0;32m    427\u001b[0m                                           \u001b[1;34m\"outputs of the user-provided function\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\autograd\\functional.py\u001b[0m in \u001b[0;36mensure_single_output_function\u001b[1;34m(*inp)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mensure_single_output_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m         \u001b[0mis_out_tuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_as_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"outputs of the user-provided function\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"hessian\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[0m_check_requires_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"outputs\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    net = MyModel().to(device)\n",
    "    optimizer = optim.Adam(net.parameters(), CFG['learning_rate'],)\n",
    "    Loss = []\n",
    "    my_loss_function = MyLoss()\n",
    "    for epoch in range(CFG['epoch']):\n",
    "        train(epoch, net, Loss)\n",
    "    test()\n",
    "    plt.plot(Loss)\n",
    "    plt.savefig('./loss')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "myloss=MyLoss()\n",
    "x=torch.tensor([[[1.,2.],[3.,4.]]],requires_grad=True)\n",
    "y=torch.zeros(2,2)\n",
    "l=myloss(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.backward(retain_graph=True,create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg=x.grad.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5000, 1.0000],\n",
       "         [1.5000, 2.0000]]], grad_fn=<CloneBackward>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.5000, 3.0000],\n",
       "         [4.5000, 6.0000]]], grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5000, 1.0000],\n",
       "         [1.5000, 2.0000]]], grad_fn=<CloneBackward>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor(1.,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=torch.tensor(0.5,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=x*w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2=torch.tensor(2.,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=w2*h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=y**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "dldw1=torch.autograd.grad(L,w1,retain_graph=True,create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4., grad_fn=<MulBackward0>),)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dldw1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dldw12=torch.autograd.grad(dldw1[0],w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(8.),)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dldw12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'csv_load'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4544e1ffb5fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'log.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_SparseArray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"module 'pandas' has no attribute '{name}'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'csv_load'"
     ]
    }
   ],
   "source": [
    "log = pd.csv_load('log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = log['lambda']\n",
    "a = log['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.DataFrame(a,index=l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='lambda'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
